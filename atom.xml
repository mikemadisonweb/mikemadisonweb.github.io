<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>todo(): redo · Mikhail Bakulin&#39;s blog</title>
  
  <subtitle>blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://mikemadisonweb.github.io/"/>
  <updated>2020-01-19T21:41:11.989Z</updated>
  <id>https://mikemadisonweb.github.io/</id>
  
  <author>
    <name>Mikhail Bakulin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Session handling with JWT</title>
    <link href="https://mikemadisonweb.github.io/2019/04/25/session-handling-with-jwt/"/>
    <id>https://mikemadisonweb.github.io/2019/04/25/session-handling-with-jwt/</id>
    <published>2019-04-25T09:00:00.000Z</published>
    <updated>2020-01-19T21:41:11.989Z</updated>
    
    <content type="html"><![CDATA[<p>Json Web Token (JWT) is a standard that defines a way how to securely transmit valuable data between distributed systems as a set of claims encoded as a JSON object (<a href="https://tools.ietf.org/html/rfc7519" target="_blank" rel="noopener">RFC7519</a>). JWT is not designed specifically for the user authorization, but for the secure data transmission between two parties in general. There are two the most widely used implementations of the JWT: JSON Web Signature and JSON Web Encoding.<br><a id="more"></a></p><h2 id="JSON-Web-Signature-JWS"><a href="#JSON-Web-Signature-JWS" class="headerlink" title="JSON Web Signature (JWS)"></a>JSON Web Signature (JWS)</h2><p>The data integrity is guaranteed by the digital signature. The token, in this case, consists of three parts:<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Javascript Object Signing and Encryption (JOSE) Headers</span></span><br><span class="line">&#123;   </span><br><span class="line">    <span class="string">"alg"</span>:<span class="string">"HS256"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// JWT Claims (Payload)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"userId"</span>: <span class="number">12234</span>,</span><br><span class="line">    <span class="string">"firstName"</span>: <span class="string">"John"</span>,</span><br><span class="line">    <span class="string">"lastName"</span>: <span class="string">"Doe"</span>,</span><br><span class="line">    <span class="string">"exp"</span>: <span class="number">1516239022</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Signature</span></span><br><span class="line">GuoUe6tw79bJlbU1HU0ADX0pr0u2kf3r_4OdrDufSfQ</span><br></pre></td></tr></table></figure></p><p>Headers provide meta information about the token. The payload may contain your arbitrary key-value data(private claims), but also could contain pre-defined keys, so-called <a href="https://tools.ietf.org/html/rfc7519#section-4.1" target="_blank" rel="noopener">registered claim names</a>, for example, “iat” (Issued At), “exp” (Expiration time), “sub” (Subject) etc. The signature is a hash string generated using the mentioned in the headers algorithm and a secret key securely stored on the sever-side.</p><p>These values are encoded with URL-safe Base64 schema and concatenated together separated by dots:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.yKOB4jkGWu7twu8Ts9zju01E10_CPedLJkoJFCan5J4</span><br></pre></td></tr></table></figure></p><p>In this form, it could be used by the client to prove his identity. The general use-cases include:</p><ul><li>pass to frontend application after the username/password authentication</li><li>pass as a cookie, like a usual stateful session ID</li><li>pass between distributed RESTful APIs as an HTTP header</li></ul><p>It is important to note that JWS implementation is signed and encoded but not encrypted anyhow. That way, the payload of the token could be easily read by all of the participants. If a malicious user would try to tamper the content, the token would be rejected by the server as it would not match the signature anymore.</p><h2 id="JSON-Web-Encoding-JWE"><a href="#JSON-Web-Encoding-JWE" class="headerlink" title="JSON Web Encoding (JWE)"></a>JSON Web Encoding (JWE)</h2><p>The JWE scheme encrypts the content instead of signing it. That way it guarantees confidentiality.<br>So in order to hide the payload content of the token, JWE could be used separately or in conjunction with JWS. To identify the JWE, one should look at the “enc” (Encryption algorithm) value in the JOSE headers. If the entry exists and not empty, it is a JWE.<br>There are two serialized forms to represent the encrypted payload: the JWE compact serialization and JWE JSON serialization. For those who are interested especially in JWE, I would recommend reading <a href="https://medium.facilelogin.com/jwt-jws-and-jwe-for-not-so-dummies-b63310d201a3" target="_blank" rel="noopener">this blog post</a>.<br>Compact serialization contain five base64Url-encoded parts separated by dots:</p><ul><li>JOSE header</li><li>JWE encrypted Key</li><li>JWE initialization vector</li><li>JWE ciphertext</li><li>JWE Authentication Tag</li></ul><p>JSON serialization is represented as a JSON object containing some or all of these eight entries:</p><ul><li>“protected” (JWE Protected Header)</li><li>“unprotected” (JWE Shared Unprotected Header)</li><li>“header” <em>(JWE Per-Recipient Unprotected Header)</em></li><li>“encrypted<em>key” </em>(JWE Encrypted Key)*</li><li>“iv” <em>(JWE Initialization Vector)</em></li><li>“ciphertext” <em>(JWE Ciphertext)</em></li><li>“tag” <em>(JWE Authentication Tag)</em></li><li>“aad” <em>(JWE Additional authenticated data)</em></li></ul><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>This is a JWT usage example of short-term tokens needed role-based CDN content access.</p><pre class="mermaid">sequenceDiagram    participant c as User    participant a as Auth server    participant b as CDN    c->>a: POST /grant-access    activate a    note right of a:Check<br>the permissions<br>based on the session    a-->>c: [200] Generated JWT    deactivate a    c->>b: POST /get-content    activate b    Note right of b: CDN validate<br>the provided JWT,<br>no session storage<br>is needed    b-->>c: [200] Content    deactivate b</pre><h2 id="Pros-and-cons-of-JWT"><a href="#Pros-and-cons-of-JWT" class="headerlink" title="Pros and cons of JWT"></a>Pros and cons of JWT</h2><h4 id="Pros"><a href="#Pros" class="headerlink" title="Pros"></a>Pros</h4><ul><li>All authentication logic could be isolated in the dedicated auth-server. Only this server will have the private key, and the rest of the servers will have the public key to verify the signature. If you have a microservice application, it promotes better architecture, because there is no direct connection between the auth-server and the rest of the servers. The authentication is done by the auth-server, and any internal API, which knows nothing about the user session, could do the authorization.</li><li>If properly implemented, the solution if fully stateless, meaning no shared session storage or sticky session solutions are needed. As a bonus, it reduces the number of queries and sometimes eliminates the need in the persistence layer at all.</li><li>Authorization when working with third-party services.</li><li>One session could be simultaneously conducted on multiple devices at the same time.</li></ul><h4 id="Cons"><a href="#Cons" class="headerlink" title="Cons"></a>Cons</h4><ul><li>The size of the token could grow out of proportions really fast if the new data is added to the token payload without control. The size of the token is adding to the size of each request, propagated to each of the microservices, and it could be an issue for the heavy load applications. Just the token containing the userId is nearly 50 times bigger than the plainly passed userId (depends on used JOSE headers and claims), so in the best scenario, the amount of data passed in the token should be small, and the extension should be forbidden.</li><li>There is no way to invalidate users partially. If JWT contains user roles, for example, or other information that could change in the process, corresponding JWT would still contain the old data until the token is expired. From the other side, if the secret key was compromised by a careless or a rogue developer/administrator, all of the users need to log out for security purposes. It could be an issue for big applications.</li><li>When implemented badly, it is nothing more than to the same plain-old stateful session handling, only in the fancy JWT wrapper. If you need to request the database to retrieve user information in nearly every API that receives a request with JWT, it is a bad sign.</li></ul><h2 id="Security-related-considerations"><a href="#Security-related-considerations" class="headerlink" title="Security-related considerations"></a>Security-related considerations</h2><p>Things that need to be done always:</p><ul><li>Both headers and payload must be signed.<br>Choose a strong algorithm. The worst case is ‘None’, which means the signature will not be checked. One should prefer ‘HS<strong><em>‘ to ‘RS</em></strong>‘ algorithms, if possible.</li><li>Store it properly on the client-side. The only good practice is to store it in a cookie, with usual restrictions like path, scope, etc.</li><li>Don’t put sensitive data in the JWS payload. These include passwords, since headers and payload are only base64encoded and not encrypted, so everyone can decode the content of JWT to get its cleartext data. Use JWE if sensitive data transmission is necessary.</li><li>Use HTTPS for all of the requests.</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By introducing JWT instead of the “old-fashioned” stateful solution you can benefit from the following:</p><ul><li>No need in a cross-cluster replicated session storage.</li><li>Propagation of the same user data to the internal APIs using a single middleware. However, JWT is not a single way how to achieve this.</li><li>Each internal API could validate the token without any external dependency.</li></ul><p>What I am trying to convey is to consider these points or make up your own before deciding to use JWT. If you have a stateful session handling already implemented, just consider the amount of refactoring that would be needed. It may not be worth the efforts. I am not against JWT at all. Some developers are confusing the idea of JWT to be a substitute for the stateful sessions. It is not true. JWT is not a new shiny way to handle sessions. It is a standard of creating tokens, which by the way, could be used for sessions, but not only. Stateless session handling makes sense in some cases, did not make sense in others. Just think about your specific situation first to make the right decision.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Json Web Token (JWT) is a standard that defines a way how to securely transmit valuable data between distributed systems as a set of claims encoded as a JSON object (&lt;a href=&quot;https://tools.ietf.org/html/rfc7519&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RFC7519&lt;/a&gt;). JWT is not designed specifically for the user authorization, but for the secure data transmission between two parties in general. There are two the most widely used implementations of the JWT: JSON Web Signature and JSON Web Encoding.&lt;br&gt;
    
    </summary>
    
    
      <category term="JWT" scheme="https://mikemadisonweb.github.io/tags/JWT/"/>
    
      <category term="Session" scheme="https://mikemadisonweb.github.io/tags/Session/"/>
    
      <category term="JSON" scheme="https://mikemadisonweb.github.io/tags/JSON/"/>
    
  </entry>
  
  <entry>
    <title>Prefix the commit message with the Jira ticket number using a git hook</title>
    <link href="https://mikemadisonweb.github.io/2018/12/18/git-hook-prepending-commit-message/"/>
    <id>https://mikemadisonweb.github.io/2018/12/18/git-hook-prepending-commit-message/</id>
    <published>2018-12-18T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.141Z</updated>
    
    <content type="html"><![CDATA[<p>The goal is to provide a way to automate the process of specifying correct ticket numbers in commit messages in order for commits to be well distinguished and linked to the corresponding tickets in the issue tracker.<br><a id="more"></a><br>Usually, git hooks are stored in .git/hooks directory inside the project repository. These files should be named according to the name of the hook, should not have any extension and should be executable.</p><p>These requirements along with the list of available hooks are described in the <a href="https://git-scm.com/docs/githooks" target="_blank" rel="noopener">git documentation</a>. However it can be tedious to set up these hooks for each project, so you can specify a global directory for the hooks like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global core.hooksPath <span class="string">'~/.git-templates/hooks'</span></span><br></pre></td></tr></table></figure></p><p>The directory name can be different.</p><p>The appropriate hook type for modifying the commit message is prepare-commit-msg as it ensures that the commit message will be edited no matter whether it was passed to the -m console flag or typed inside the text editor.</p><p>So we need to create a file <code>~/.git-templates/hooks/prepare-commit-msg</code> with the following Bash script:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Include any branches for which you wish to disable this script</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$BRANCHES_TO_SKIP</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">  BRANCHES_TO_SKIP=(master develop)</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment"># Get the current branch name</span></span><br><span class="line">BRANCH_NAME=$(git symbolic-ref --short HEAD)</span><br><span class="line"><span class="comment"># Ticket name is retrieved as a string between the first slash and the second hyphen</span></span><br><span class="line">TICKET_NAME=$(<span class="built_in">echo</span> <span class="variable">$BRANCH_NAME</span> | sed -e <span class="string">'s/^[^\/]*\/\([^-]*-[^-]*\)-.*/\1/'</span>)</span><br><span class="line"></span><br><span class="line">BRANCH_EXCLUDED=$(<span class="built_in">printf</span> <span class="string">"%s\n"</span> <span class="string">"<span class="variable">$&#123;BRANCHES_TO_SKIP[@]&#125;</span>"</span> | grep -c <span class="string">"^<span class="variable">$BRANCH_NAME</span>$"</span>)</span><br><span class="line">ALREADY_IN_MSG=$(grep -c <span class="string">"<span class="variable">$TICKET_NAME</span>"</span> <span class="variable">$1</span>)</span><br><span class="line"><span class="comment"># If it isn't excluded or already in commit message, prepend the ticket name to the given message</span></span><br><span class="line"><span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$BRANCH_NAME</span>"</span> ] &amp;&amp; ! [[ <span class="string">"<span class="variable">$BRANCH_EXCLUDED</span>"</span> -eq 1 ]] &amp;&amp; ! [[ <span class="string">"<span class="variable">$ALREADY_IN_MSG</span>"</span> -eq 1 ]]; <span class="keyword">then</span></span><br><span class="line">    sed -i.bak -e <span class="string">"1s/^/<span class="variable">$TICKET_NAME</span> /"</span> <span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p><p>In this script, we assume that the ticket number is a project name separated with an auto-incremental number by a hyphen and it exists in the name of the branch. This assumption is valid most of the times as it is a usual naming convention for the Atlassian Stack(Jira, Bitbucket etc) </p><p>During the execution of the script the ticket number will be parsed from the name of the branch upon commit creation and added to the message. This script will be skipped for master and develop branches and it will check if the ticket number is already inside the message to restrict it to be added twice.</p><p>If in some case there is no need to use this hook it can be skipped on commit using –no-verify flag.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The goal is to provide a way to automate the process of specifying correct ticket numbers in commit messages in order for commits to be well distinguished and linked to the corresponding tickets in the issue tracker.&lt;br&gt;
    
    </summary>
    
    
      <category term="Git" scheme="https://mikemadisonweb.github.io/tags/Git/"/>
    
      <category term="Git hook" scheme="https://mikemadisonweb.github.io/tags/Git-hook/"/>
    
      <category term="Jira" scheme="https://mikemadisonweb.github.io/tags/Jira/"/>
    
  </entry>
  
  <entry>
    <title>How to debug Golang applications inside Docker containers using Delve</title>
    <link href="https://mikemadisonweb.github.io/2018/06/14/go-remote-debug/"/>
    <id>https://mikemadisonweb.github.io/2018/06/14/go-remote-debug/</id>
    <published>2018-06-14T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.150Z</updated>
    
    <content type="html"><![CDATA[<p>Suppose you have multiple Go microservices each one acting like a web server in our application architecture and you stuck with some subtle bug which drives you crazy. You might be also tired of putting variables of your interest inside formatted output of some sort of logger to see their current values. If you are looking for a better way of debugging Go code and you are not willing to give up using Docker, this article can help you.<br><a id="more"></a><br>All the code regarding this article can be found on <a href="https://github.com/mikemadisonweb/go-debug-example" target="_blank" rel="noopener">GitHub</a> so feel free to experiment with it.</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>As the time running by more and more developers all over the world are turning into facilitating Docker to setup local environment on their computers. There are multiple reasons behind it:</p><ul><li>process isolation, configurable resource usage, and network restrictions</li><li>fast setup and declarative configuration, which is self-describing for new team members</li><li>repeatable setup on multiple development stages</li><li>centralized version control for project dependencies</li><li>large community if you need an advice</li><li>Docker Hub registry if you are looking for Docker images that are open-source and ready to use</li></ul><p>However, it’s not an article about Docker per se. I just mean that despite allowing a huge amount of advantages Docker also challenges us to find new ways of developing and debugging our applications. In <a href="/2018/03/06/go-autoreload/">previous article</a> I have posted my Go auto-reload setup for development, this time I will reveal my way of debugging code inside Go containers. Rather then old-school console debuggers like <a href="https://golang.org/doc/gdb" target="_blank" rel="noopener">GDB</a>, I prefer using IDE integration with Delve which allows to see all the variables at once and to jump between stack frames or breakpoints easily. I will use JetBrains GoLand, but I think it can be used the same way with the most of other IDE and <a href="https://github.com/sebdah/vim-delve" target="_blank" rel="noopener">even with vim</a>.</p><h3 id="Building-image"><a href="#Building-image" class="headerlink" title="Building image"></a>Building image</h3><p>The easiest way of installing Delve debugger is to use <code>go get</code> command. After ensuring proper directory structure and adding needed dependencies to base Golang image debugger can be installed:<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.10</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> root /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> GOPATH /go</span><br><span class="line"><span class="keyword">ENV</span> PATH $GOPATH/bin:/usr/local/go/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk add --no-cache ca-certificates \</span></span><br><span class="line"><span class="bash">        dpkg \</span></span><br><span class="line"><span class="bash">        gcc \</span></span><br><span class="line"><span class="bash">        git \</span></span><br><span class="line"><span class="bash">        musl-dev \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mkdir -p <span class="string">"<span class="variable">$GOPATH</span>/src"</span> <span class="string">"<span class="variable">$GOPATH</span>/bin"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod -R 777 <span class="string">"<span class="variable">$GOPATH</span>"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod +x /entrypoint.sh \</span></span><br><span class="line"><span class="bash">    &amp;&amp; go get github.com/derekparker/delve/cmd/dlv</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$GOPATH</span></span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/entrypoint.sh"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"dlv"</span>, <span class="string">"debug"</span>, <span class="string">"--headless"</span>, <span class="string">"--listen=:2345"</span>, <span class="string">"--api-version=2"</span>]</span></span><br></pre></td></tr></table></figure></p><p>I tried to make this Dockerfile reusable between different microservices. That’s why I added entrypoint.sh script to the image which changes the current directory before starting the container to the one that contains needed main.go file:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GO_WORK_DIR=<span class="variable">$&#123;GO_WORK_DIR:-$GOPATH/src&#125;</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;GO_WORK_DIR&#125;</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure></p><p>So all that we need to do for using this image by multiple different applications is to pass GO_WORK_DIR environment variable to container upon creation. If you want to share the GO_PROJECT_DIR variable between team members you can add its value to .env file and push it to the repository.<br>Running Delve in headless mode means that only server part will be executed, with will listen for external connections on port 2345. Configuring container in docker-compose then will be trivial with one little exception, custom security option should be added in order for Delve to work inside the container:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">app:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">"app"</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">"./docker/go-debug"</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">".:$&#123;GO_PROJECT_DIR&#125;"</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">GO_WORK_DIR:</span> <span class="string">"$&#123;GO_PROJECT_DIR&#125;/app"</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"8080:8080"</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"2345:2345"</span></span><br><span class="line">    <span class="attr">security_opt:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"seccomp:unconfined"</span></span><br></pre></td></tr></table></figure></p><p>Any attempt to start a container without this option will face an error: <code>could not launch process: fork/exec [...]: operation not permitted</code>.</p><p>Now that we have our container up and running Delve is waiting for a connection. Let’s add configuration in GoLand to start a debugging session:</p><p><img src="go-debug-configuration-ide.png" alt="delve goland ide configuration example"></p><p>If you have tried any debugger before in any other IDE then everything else will look familiar to you. Debugging session can be started by hitting green bug button. If you place a breakpoint on a line with Go server initialization, execution will be immediately stopped on it. Otherwise, proceed to <code>localhost:8080</code> to debug your request handling function:</p><p><img src="go-debug-breakpoint.png" alt="delve goland ide breakpoint example"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Suppose you have multiple Go microservices each one acting like a web server in our application architecture and you stuck with some subtle bug which drives you crazy. You might be also tired of putting variables of your interest inside formatted output of some sort of logger to see their current values. If you are looking for a better way of debugging Go code and you are not willing to give up using Docker, this article can help you.&lt;br&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="https://mikemadisonweb.github.io/tags/Golang/"/>
    
      <category term="Docker" scheme="https://mikemadisonweb.github.io/tags/Docker/"/>
    
      <category term="Docker-compose" scheme="https://mikemadisonweb.github.io/tags/Docker-compose/"/>
    
      <category term="Delve" scheme="https://mikemadisonweb.github.io/tags/Delve/"/>
    
      <category term="JetBrains GoLand" scheme="https://mikemadisonweb.github.io/tags/JetBrains-GoLand/"/>
    
  </entry>
  
  <entry>
    <title>Running Golang applications inside Docker containers with auto reload</title>
    <link href="https://mikemadisonweb.github.io/2018/03/06/go-autoreload/"/>
    <id>https://mikemadisonweb.github.io/2018/03/06/go-autoreload/</id>
    <published>2018-03-06T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.146Z</updated>
    
    <content type="html"><![CDATA[<p>The nature of Golang web application complicates the development process a bit, as a program needs to be compiled and executed in order to listen some specific port for incoming requests. During the development process feature of reloading your app automatically on file change can save a huge amount of time. It can become even harder when you use Docker containers in the local environment for your Golang microservices. This article provides a real-life example of a such an auto-reloading setup.<br><a id="more"></a></p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Every newcomer to Golang usually come up with his/her own way of executing an app, whether using console commands or hitting buttons inside IDE. After a while, it becomes really tedious to performs the same operations manually over and over again on codebase update in order to see the changes in a browser. Most of you who faced frontend development workflow and tools like gulp and webpack are already familiar with a concept of auto reload. The main idea behind it that you have a daemon which responsibility is to monitor files inside a project for changes and repeat the needed processing upon update. It is equally suitable for Golang apps and there are already a bunch of packages on GitHub that offers that functionality, so there is no need for reinventing the wheel. In this article, we will use <a href="https://gorealize.io/" target="_blank" rel="noopener">Realize</a> library as I find it the most advanced in terms of features, performance and configuration options.</p><p>We would boost the workflow even more by leveraging Docker containers, if you are not familiar with it please spend some time on understanding the basics of Docker, I promise that you will not regret it. Inside a container we will run Realize instead of complaining or executing main.go directly and after all, there would be no need to restart container during the development of an app.</p><p>I have put all of the code regarding this article into a <a href="https://github.com/mikemadisonweb/go-autoreload-example" target="_blank" rel="noopener">git repository</a> so you can check it out in order to try everything by yourself and make sure how handy it can be.</p><h3 id="Building-a-Docker-container"><a href="#Building-a-Docker-container" class="headerlink" title="Building a Docker container"></a>Building a Docker container</h3><p>Suppose you have an application that is consist of multiple microservices. I know that this term has got highly abused in past few years, but let’s not dive deeper into the details and just suppose we have multiple Golang apps each one represents a web server. In order to free yourself from running them in separate terminals and don’t worry about possible interferences<br>with other projects, we will put all of them into containers using docker-compose.</p><p>But let’s start with a single app, put a docker-compose config into the root of your project:<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">app:</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">"app"</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">"./docker/go-develop"</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">".:$&#123;GO_PROJECT_DIR&#125;"</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"8080:8080"</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="attr">GO_WORK_DIR:</span> <span class="string">"$&#123;GO_PROJECT_DIR&#125;/app"</span></span><br></pre></td></tr></table></figure></p><p><code>GO_PROJECT_DIR</code> environment variable stands for the path of the project files inside of the container, as you probably know Go code should be <a href="https://golang.org/doc/code.html" target="_blank" rel="noopener">properly structured</a>.</p><p>So this service definition tells docker-compose utility to build an image from Dockerfile located in “./docker/go-develop” in order to run an “app” container based on that image. Project files should be mounted to the container and port 8080 should be forwarded to the host machine to receive the requests from the browser. Let’s look what inside of the Dockerfile:<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.9</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> root /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk add --no-cache ca-certificates \</span></span><br><span class="line"><span class="bash">        dpkg \</span></span><br><span class="line"><span class="bash">        gcc \</span></span><br><span class="line"><span class="bash">        git \</span></span><br><span class="line"><span class="bash">        musl-dev \</span></span><br><span class="line"><span class="bash">        bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> GOPATH /go</span><br><span class="line"><span class="keyword">ENV</span> PATH $GOPATH/bin:/usr/local/go/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p <span class="string">"<span class="variable">$GOPATH</span>/src"</span> <span class="string">"<span class="variable">$GOPATH</span>/bin"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod -R 777 <span class="string">"<span class="variable">$GOPATH</span>"</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; chmod +x /entrypoint.sh</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go get github.com/tockins/realize</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$GOPATH</span></span></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/entrypoint.sh"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"realize"</span>, <span class="string">"start"</span>]</span></span><br></pre></td></tr></table></figure></p><p>Even if you don’t know the syntax most of the instructions are self-explanatory. Besides installing needed dependencies and realize package there is an important operation. We are adding entrypoint.sh from the host machine, setting the executing permissions on it and mark the script as an entrypoint. The latter means that it would be executed before the main process inside a container and that is exactly what we need to reuse that image between multiple Golang applications.</p><p>All of that script does is just changing the directory before realize get started:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line">GO_WORK_DIR=<span class="variable">$&#123;GO_WORK_DIR:-$GOPATH/src&#125;</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$&#123;GO_WORK_DIR&#125;</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure></p><p>The reason behind introducing this entrypoint is that realize process will look for a main.go file inside of the current directory. It will also use the configuration(.realize.yaml) if it is present inside the directory, so you can tune the behavior of the realize depending on the app needs.</p><h3 id="Auto-reload"><a href="#Auto-reload" class="headerlink" title="Auto reload"></a>Auto reload</h3><p>In the main.go file we will put really basic web server implementation:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"net/http"</span></span><br><span class="line">    <span class="string">"log"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    fmt.Fprintf(w, <span class="string">"You have visited %s!"</span>, r.URL.Path)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    http.HandleFunc(<span class="string">"/"</span>, handle)</span><br><span class="line">    fmt.Println(<span class="string">"Starting web server on port 8080"</span>)</span><br><span class="line">    err := http.ListenAndServe(<span class="string">":8080"</span>, <span class="literal">nil</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        log.Fatal(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Nothing that fancy, but if you run <code>docker-compose up</code> inside your project root directory it will set up an app and then you can visit <code>http://localhost:8080/</code> with your browser to get the message “You have visited /!”. </p><p>All good so far, let’s try changing something inside our handle function. Just change the welcome message slightly, check the console to see how realize reloading the app:<br><img src="go-autoreload-1.png" alt="realize golang auto reload example"></p><p>Just refresh the page and voila! The message has been changed. Now let’s try to introduce another app into our setup.</p><h3 id="Multiple-applications"><a href="#Multiple-applications" class="headerlink" title="Multiple applications"></a>Multiple applications</h3><p>For the sake of an example I will add another application and to reduce code duplication I will reuse some part of the code(<code>common</code> directory):<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> common</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"net/http"</span></span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"log"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> AppName = <span class="string">"app"</span></span><br><span class="line"><span class="keyword">const</span> AnotherAppName = <span class="string">"another-app"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">StartServer</span><span class="params">(port <span class="keyword">string</span>, handlerFunc http.HandlerFunc)</span></span> &#123;</span><br><span class="line">    http.HandleFunc(<span class="string">"/"</span>, handlerFunc)</span><br><span class="line">    fmt.Println(<span class="string">"Starting web server on port "</span> + port)</span><br><span class="line">    err := http.ListenAndServe(<span class="string">":"</span> + port, <span class="literal">nil</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        log.Fatal(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>And the application bootstrap now looks the following way:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"net/http"</span></span><br><span class="line">    <span class="string">"github.com/mikemadisonweb/go-autoreload-example/common"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">    fmt.Fprintf(w, <span class="string">"You have visited %s in `%s`!"</span>, r.URL.Path, common.AppName)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    common.StartServer(<span class="string">"8080"</span>, handle)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>After adding service definition inside docker-compose.yaml and restarting docker-compose we will end up with two containers listening for requests on ports 8080 and 8181. But the most exciting part is even if you put an extra new line to common.go file and save the file, both applications will automatically recompile within a fraction of a second:<br><img src="go-autoreload-2.png" alt="realize golang auto reload multiple app example"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The nature of Golang web application complicates the development process a bit, as a program needs to be compiled and executed in order to listen some specific port for incoming requests. During the development process feature of reloading your app automatically on file change can save a huge amount of time. It can become even harder when you use Docker containers in the local environment for your Golang microservices. This article provides a real-life example of a such an auto-reloading setup.&lt;br&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="https://mikemadisonweb.github.io/tags/Golang/"/>
    
      <category term="Docker" scheme="https://mikemadisonweb.github.io/tags/Docker/"/>
    
      <category term="Docker-compose" scheme="https://mikemadisonweb.github.io/tags/Docker-compose/"/>
    
      <category term="Realize" scheme="https://mikemadisonweb.github.io/tags/Realize/"/>
    
  </entry>
  
  <entry>
    <title>10 useful shell tools to boost web developer workflow</title>
    <link href="https://mikemadisonweb.github.io/2017/09/18/10_useful_shell_tools/"/>
    <id>https://mikemadisonweb.github.io/2017/09/18/10_useful_shell_tools/</id>
    <published>2017-09-18T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.138Z</updated>
    
    <content type="html"><![CDATA[<p>Tips and tricks presented in this article are not essential to build a web application, but when you do stuff in a command line environment in your day to day work it can boost your productivity drastically.<br><a id="more"></a><br>All tools presented here are small utilities that are just making your life easier, none of these can be considered a lifesaver software. However little things that can become a big deal for you in a long run. I will add examples to each part, but I can’t guarantee the correctness of syntax between all Linux distributions and MacOS, as it can vary slightly. If you want to use these on Windows I can recommend you to use a terminal emulator, like <a href="http://babun.github.io/" target="_blank" rel="noopener">Babun</a>. Certain keywords like <code>filename</code> and <code>command</code> will be used as placeholders to actual filename.</p><h2 id="1-head-amp-tail"><a href="#1-head-amp-tail" class="headerlink" title="1: head &amp; tail"></a>1: head &amp; tail</h2><p>Most of you are probably familiar with <code>head</code> and <code>tail</code> commands, but not everyone knows that they can do more than just to print first and last parts of files respectfully. Using simple shell magic we can, for example, truncate a file to the number of lines from the beginning:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 100 filename | tee filename</span><br></pre></td></tr></table></figure></p><p>To append these lines to the end of a file instead:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -n 100 filename &gt;&gt; filename</span><br></pre></td></tr></table></figure></p><p>Next one is more practical, as you can monitor your logs in real-time:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -F filename</span><br></pre></td></tr></table></figure></p><p>Beware that options <code>-f</code> and <code>-F</code> in tail command is very similar, but have one significant distinction. The <code>-F</code> option will keep track of changes based on the filename and not the inode number, that could change during log rotation.</p><h2 id="2-sed"><a href="#2-sed" class="headerlink" title="2: sed"></a>2: sed</h2><p>One of the tools that can be really handy when you need to apply certain manipulations on a text file. Search and replace based on regular expressions can be done relatively fast and easy even if the file is too big to open it in a text editor. To replace all occurrences of a string in a file, overwriting the file you can run the following command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'s/find/replace/g'</span> filename</span><br></pre></td></tr></table></figure></p><p>However, that is not all you can do with it. If you only need to count lines in a file:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'$='</span> filename</span><br></pre></td></tr></table></figure></p><p>As I said <code>tail</code> and <code>head</code> commands can give you some portion of data from the end or the beginning of the file, but what if I need something in the middle. Let’s suppose that I know exact line numbers on which needed text resides:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'55,60p'</span> filename</span><br></pre></td></tr></table></figure></p><p>It will print all the contents between 55th and 60th lines.<br>Same in-place truncation that’s can be done with <code>head</code>(first one in this article), can be easily done with <code>sed</code> as well:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'101,$ d'</span> filename</span><br></pre></td></tr></table></figure></p><p>It would delete all lines in a file starting from 101.</p><h2 id="3-gnomon"><a href="#3-gnomon" class="headerlink" title="3: gnomon"></a>3: gnomon</h2><p>The next one is not a built-in Linux utility and it is written in Javascript by Paypal. It prepends standard output with timestamp information, so you can profile execution time of your scripts. This is how I benchmark query execution in MongoDB that is located in Docker container:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -i mongo mongo dbname --quiet &lt; benchmark | gnomon</span><br></pre></td></tr></table></figure></p><p>By piping scripts to gnomon, you will get each line time elapsed from the previous line or the beginning of script execution, based on passed options.</p><p>You can install it globally using npm or yarn:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn global add gnomon</span><br></pre></td></tr></table></figure></p><h2 id="4-grep"><a href="#4-grep" class="headerlink" title="4: grep"></a>4: grep</h2><p>Most of you are probably already familiar with <code>grep</code>, but talking about stuff you can do with pipes, I can’t leave this one unmentioned. By all means <code>grep</code> can be used without a pipe, but that is where it really shines for a web developer:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">php -i | grep <span class="string">'pgsql'</span></span><br></pre></td></tr></table></figure></p><p>That way you can filter any command output using patterns or regular expressions. In addition to that, you can use <code>-n</code> option to show line numbers for each match, <code>-c</code> to print count of matches instead and a bunch of others.</p><h2 id="5-jq"><a href="#5-jq" class="headerlink" title="5: jq"></a>5: jq</h2><p>As you probably used to deal with JSON a lot, jq is a small sed-like tool that can save you a lot of time. Let’s say you receive some JSON-data from a remote application and you want to pretty-print it to make it more readable. Then just pipe it to jq with <code>.</code> as a filter:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'&#123;"result":&#123; "some":&#123;"random":"data"&#125;&#125;&#125;'</span> | jq .</span><br></pre></td></tr></table></figure></p><p>Here I just simulated remote call with <code>echo</code>, the result output would be:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"result"</span>: &#123;</span><br><span class="line">    <span class="string">"some"</span>: &#123;</span><br><span class="line">      <span class="string">"random"</span>: <span class="string">"data"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>The output can be filtered further like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'&#123;"result":&#123; "some":&#123;"random":"data"&#125;&#125;&#125;'</span> | jq .result.some.random</span><br></pre></td></tr></table></figure></p><p>It will print <code>&quot;data&quot;</code>, could it be easier than that? In a JSON cumbersome mess jq can be your guide.</p><h2 id="6-make"><a href="#6-make" class="headerlink" title="6: make"></a>6: make</h2><p>Let’s look at <code>make</code> utility from an unusual point of view. We all know it as dependency-tracking build utility, but it can be used as a task runner. The main benefit of it is that <code>make</code> is available on every Unix-like system, no installation is needed and you can put Makefile with a bunch of project related tasks in your repository and do not worry about another developer would not be able to run it. But why even bother with task runners in the first place? Some shell commands are useful but it’s painful to remember them as they are long and hard to remember. The most common solution is to make an alias in your system to make that command easier to remember and faster to type. But every project might have its own set of handy commands, so it is not a good idea to keep it in one place and it can be advantageous to share these with other developers. This is an example of Makefile contents made for my Go project:<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">unit_test:</span></span><br><span class="line">    @<span class="variable">$(<span class="built_in">call</span> PRINT_INFO, "Run unit-tests")</span></span><br><span class="line">    @go test -v $<span class="variable">$(go list ./app/... | grep -v excluded_dir)</span></span><br><span class="line"></span><br><span class="line"><span class="section">fmt:</span></span><br><span class="line">    @<span class="variable">$(<span class="built_in">call</span> PRINT_INFO, "Format")</span></span><br><span class="line">    @go fmt $<span class="variable">$(go list ./app/... | grep -v excluded_dir)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">define</span> PRINT_INFO</span><br><span class="line">    echo -e <span class="string">"\033[1;48;5;33m$1 \033[0m"</span></span><br><span class="line"><span class="keyword">endef</span></span><br></pre></td></tr></table></figure></p><p>Parameters and environment variables can be used in Makefile as well, but be advised that make is using its own syntax that is different from Bash and it accepts only tabs as indentation.</p><h2 id="7-awk"><a href="#7-awk" class="headerlink" title="7: awk"></a>7: awk</h2><p>To work with text more like rows and columns, rather than patterns, I will recommend using <code>awk</code> over <code>sed</code>. It can be really convenient for file formats, like csv and tsv. For example, if you want to sum the values in the second column of a file and print the total:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'&#123;s+=$2&#125; END &#123;print s&#125;'</span> filename</span><br></pre></td></tr></table></figure></p><p>To use comma as a field separator instead of space <code>-F</code> option can be used. This is how can you print contents of a file without any duplicate rows:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">'!($0 in array) &#123; array[$0]; print &#125;'</span> filename</span><br></pre></td></tr></table></figure></p><p>Despite the fact that it can be done more elegant with <code>uniq</code>, I think you got the point. With <code>awk</code> you can write your own mini-scripts to apply on a text file.</p><h2 id="8-curl"><a href="#8-curl" class="headerlink" title="8: curl"></a>8: curl</h2><p>I advocate using <code>curl</code> whenever data needs to be sent or received in a command-line environment. But let’s start with a fun part. There is a fast way to figure out your IP address, just type one of those:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl wtfismyip.com/text</span><br><span class="line">curl wgetip.com</span><br><span class="line">curl ifcfg.me</span><br><span class="line">curl eth0.me</span><br></pre></td></tr></table></figure></p><p>There is basically no need to click anything to do that. Moreover, you can get the weather forecast:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl wttr.in</span><br></pre></td></tr></table></figure></p><p><img src="curl_weather.png" alt="curl weather forecast"><br>Back to work, if you need to debug some particular request and you are using Google Chrome, head on to DevTools, choose Network tab, find a request of interest and right-click on it. In the popup menu under the ‘Copy’ group, there is a ‘Copy as cURL’. That’s awesome! Now you can paste it into Terminal, debug and change it as you wish.</p><h2 id="9-bg-amp-fg"><a href="#9-bg-amp-fg" class="headerlink" title="9: bg &amp; fg"></a>9: bg &amp; fg</h2><p>Any process that was executed from shell can be rather run in the foreground, that means that it blocks a terminal window, no new processes can not run until that initial one stops or in the background, that can be considered as an asynchronous way. There is nothing too advanced about these features, but it worth noting that any process that was started in foreground can be suspended using <code>ctrl+z</code> keyboard shortcut, monitored using <code>jobs</code> command, resumed by <code>fg</code>, sent to background using <code>bg</code> or stopped by <code>kill %n</code> command where n is a number of a job.<br>To run a process in the background, to begin with, just append an ampersand (&amp;) to the command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">command</span> &amp;</span><br></pre></td></tr></table></figure></p><h2 id="10-Bash-alternatives"><a href="#10-Bash-alternatives" class="headerlink" title="10: Bash alternatives"></a>10: Bash alternatives</h2><p>It is important to personalize your working environment the way that suits you. So it can be beneficial to experiment a bit with various programs and frameworks. My personal preference is Z shell over Bash, as it has all advantages of Bash with several additional features. There is a decent overview of Zsh in a <a href="https://www.slideshare.net/jaguardesignstudio/why-zsh-is-cooler-than-your-shell-16194692" target="_blank" rel="noopener">presentation</a> by Brendon Rapp that is worth looking. If you are curious, there is a whole lot of <a href="https://github.com/alebcay/awesome-shell" target="_blank" rel="noopener">awesome stuff</a> you can discover that will enhance your user experience. </p><p>I can recommend <a href="https://github.com/robbyrussell/oh-my-zsh" target="_blank" rel="noopener">Oh-my-zsh</a> for styling, <a href="https://github.com/rupa/z" target="_blank" rel="noopener">Z script</a> for easy navigation and <a href="https://github.com/zsh-users/zsh-syntax-highlighting" target="_blank" rel="noopener">Fish syntax highlighting</a> to make commands look clearer:<br><img src="fish_syntax_highlighting.png" alt="Fish shell like syntax highlighting"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Tips and tricks presented in this article are not essential to build a web application, but when you do stuff in a command line environment in your day to day work it can boost your productivity drastically.&lt;br&gt;
    
    </summary>
    
    
      <category term="Unix" scheme="https://mikemadisonweb.github.io/tags/Unix/"/>
    
      <category term="Shell" scheme="https://mikemadisonweb.github.io/tags/Shell/"/>
    
      <category term="Bash" scheme="https://mikemadisonweb.github.io/tags/Bash/"/>
    
  </entry>
  
  <entry>
    <title>TL;DR Series - RabbitMQ introduction</title>
    <link href="https://mikemadisonweb.github.io/2017/05/04/tldr-series-rabbitmq/"/>
    <id>https://mikemadisonweb.github.io/2017/05/04/tldr-series-rabbitmq/</id>
    <published>2017-05-04T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.158Z</updated>
    
    <content type="html"><![CDATA[<p>Yet another RabbitMQ introduction. If you are looking for an article about RabbitMQ, there are plenty of them and most of them are really good. Nevertheless, I decided to make my own contribution. So considering an amount of information out there about RabbitMQ, what makes this article different? I will try to keep it short, meaningful and practical while not falling into a bottomless pit of details. I do not mean that there are something that is not worth to know about, just let’s try it this way. Consider it as TL;DR for the topic.<br><a id="more"></a></p><h1 id="Why-you-might-need-it"><a href="#Why-you-might-need-it" class="headerlink" title="Why you might need it"></a>Why you might need it</h1><p>If you planning to increase the complexity of your app, you should have very strong reasons behind it. Otherwise, it can be an overkill. That’s when you probably should consider using RabbitMQ:</p><ul><li>If you need more flexibility. Your little services can talk to each other through RabbitMQ. It decouples your code and provides ability to write services in different programming languages.</li><li>If you want to organize and monitor your data flow. The powerful routing system of RabbitMQ gives you an ability to implement whatever logic you might need.</li><li>If you need durability. After the message was created it will be delivered sooner or later, if you don’t tell RabbitMQ to drop it explicitly. Also, the order of messages gets preserved. </li><li>If it’s used in the right way it can also increase clarity, making things more obvious. So it helps to clarify data flow of your application and provide extensibility, but it gets even better(with languages like PHP) because it’s a way to make things asynchronous. Your users won’t be forced to wait too long for a response without any particular reason. You can postpone thing like sending notifications or convert an uploaded photo, everything that’s not necessary needed right away.</li><li>If you need highly-available queues. RabbitMQ cluster can be configured without any additional software.</li><li>RabbitMQ is highly extensible and there are a lot of external plugins available, that you can use if you need something special.</li></ul><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Basically, you need to extract functionality of choice into a daemon which will run infinitely in the console (consumer) waiting for a message to be sent to it (producer). If you are familiar with publish–subscribe pattern, it’s a very close concept. You send a message containing payload data and some additional information which identifies the destination of that message. There can be multiple consumers and producers, that’s why we need RabbitMQ to control message routing and guarantee the delivery. </p><p><img src="rabbitmq1.png" alt="multiple producers -&gt; broker -&gt; multiple consumers"></p><p>Let’s get ourselves familiar with some key definitions of messaging systems and RabbitMQ in particular. For each one of them, I will describe briefly its purpose and available configuration options.</p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p>In the context of this article, it’s RabbitMQ. A software in charge of delivering messages, aka message-oriented middleware.</p><h3 id="Protocol"><a href="#Protocol" class="headerlink" title="Protocol"></a>Protocol</h3><p>By default RabbitMQ use Advanced Messaging Queue Protocol (AMQP), however also support a bunch of others. If you want to compare it to HTTP, then AMQP is much more specific: </p><ul><li>it is a <a href="http://www.amqp.org/resources/developer-faqs#q3" target="_blank" rel="noopener">wire protocol</a></li><li>it is binary</li><li>it is bidirectional, meaning both  RabbitMQ and your application can send remote procedure calls.</li><li>it has lower overhead</li><li>it is asynchronous.<br>Probably the most important thing you should know about AMQP is that it provides a mechanism for delivery and processing confirmation, known as acknowledgments.<br>I would stick to AMQP version 0-9-1 in this article because it’s well known, commonly used and natively supported by most programming languages.</li></ul><h3 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h3><p>A connection is a TCP connection between your application and the RabbitMQ broker.</p><h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>A channel is a virtual connection inside a connection. When you are publishing or consuming messages from a queue - it’s all done over a channel.</p><h3 id="Users"><a href="#Users" class="headerlink" title="Users"></a>Users</h3><p>It is possible to connect to RabbitMQ with a given username and password. Every user can be assigned permissions such as rights to read, write and configure privileges within the instance. Users can also be assigned permissions to specific virtual hosts.</p><h3 id="Vhost-virtual-host"><a href="#Vhost-virtual-host" class="headerlink" title="Vhost, virtual host"></a>Vhost, virtual host</h3><p>A Virtual host provides a way to segregate applications using the same RabbitMQ instance. Different users can have different access privileges to different vhost and queues and exchanges can be created so they only exist in one vhost.</p><h3 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h3><p>An application that sends the messages. Producers need to establish a TCP connection to create a channel and then publish messages with corresponding routing keys.</p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p>An application that receives messages from a queue. Сonsumer connects to a queue and receives one or more messages. You can get the better throughput consuming multiple messages at a time, but it depends on your circumstances. When you have multiple consumers connected to a single queue, messages are distributed using round-robin technique.</p><h3 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h3><p>Exchange is a message entrypoint. Producer publishes message to an exchange and it defines where should it go next. It can clone the message and send it to multiple queues, pass it to another exchange, the are lots of possibilities, which are determined based on multiple factors.<br>In terms of the algorithm used to route a message four types of exchanges exists:</p><ul><li><strong>Direct</strong> : Routing key matches the queue name.</li><li><strong>Fanout</strong> : The message is cloned and sent to all queues connected to this exchange. Routing key is ignored.</li><li><strong>Topic</strong> : Using wildcards the message can be routed to some of the connected queues.</li><li><strong>Headers</strong> : Attributes used for routing are taken from the header values, not routing key.</li></ul><p>You can find a really good visual representation of exchange types <a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_MRG/1.1/html/Messaging_User_Guide/chap-Messaging_User_Guide-Exchanges.html#sect-Messaging_User_Guide-Exchanges-Exchange_Types" target="_blank" rel="noopener">here</a>.<br>On declaring an exchange you should define a name and type as it is mandatory, there is a bunch of optional parameters though:</p><ul><li><strong>passive</strong> : If set to true, server would not raise error when exchange already exists.</li><li><strong>durable</strong> : Durable exchange remains active upon restart. To clarify I will note that exchanges do not store messages as queues do.</li><li><strong>auto-delete</strong> : If there is no queues bind to an exchange it gets automatically deleted.</li><li><strong>arguments</strong> : Set of arbitrary arguments.</li></ul><h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>Queue in RabbitMQ is a place where messages waiting to be consumed. As in any other queue first come first served principle stand strong here. Message order is so important that if message processing raises an error within consumer, it should be rejected explicitly to be dropped or sent to the end of the queue. Otherwise, it is possible to set <code>no-ack</code> property when consume, so server would not wait for consumer to set acknowledgment. Most of the times it will increase performance but at the cost of reliability.<br>Queue stores messages in memory and optionally on disk, you can set delivery-mode parameter upon message publish to control whether message should be persisted on disk or not.<br>There are a number of options you can set when declaring new query, most useful of them are:</p><ul><li><strong>name</strong> : You can pass name to identify the queue if the name is not specified it’s randomly generated. This can be useful when you need temporary and anonymous queues for RPC-over-AMQP.</li><li><strong>passive</strong> : If set to true server would not raise error when queue already exists.</li><li><strong>durable</strong> : Durable queue remains active and preserves persistent messages upon restart.</li><li><strong>exclusive</strong> : Exclusive queue may only be accessed by current connection and gets deleted when connection closes.</li><li><strong>auto-delete</strong> : If there are no consumers using a queue it gets automatically deleted.</li><li><strong>arguments</strong> : Set of arbitrary arguments. For example, <code>x-message-ttl</code> defines how long a message published to a queue can live before it is discarded(Time-To-Live) and <code>x-dead-letter-exchange</code> is name of an exchange to which messages will be republished if they are rejected or expire.</li></ul><h3 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h3><p>Bindings are rule-sets for distributing messages from exchanges to queues. Upon creating a binding the most important parameter is <code>routing-key</code>, as it is defining the way messages will be routed.</p><p><img src="rabbitmq2.png" alt="multiple producers -&gt; exchange - binding - queue -&gt; multiple consumers"></p><h3 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h3><p>Some structured amount of binary data that is sent from the producer to a consumer through RabbitMQ. AMQP message usually comprised of three main parts(frames):</p><ul><li><strong>Method frame</strong> : For example, when we are publishing a message, our application calls Basic.Publish, and this metadata is carried in a method frame, that will tell RabbitMQ that a client is going to publish a message.</li><li><strong>Headers</strong> : These are properties defined by the AMQP specification and additional user properties. They are used by the broker for manipulation, routing and so on.</li><li><strong>Body</strong> : User defined payload of the message. Can be split into multiple different frames if the message is too big (131KB is the default frame size limit).<br>There are also two connection-specific types of frames:</li><li><strong>Protocol header</strong> : This is the frame sent to establish a new connection.</li><li><strong>Heartbeat</strong> : Used to confirm that a given client is still alive.</li></ul><h3 id="Routing-key"><a href="#Routing-key" class="headerlink" title="Routing key"></a>Routing key</h3><p>Routing key is an arbitrary string attached to a message. It should be defined by client application(producer) before dispatch to determine needed routing. For example, direct exchange compares message routing key against keys of existing bindings and send message clone on match.</p><h3 id="Quality-of-service"><a href="#Quality-of-service" class="headerlink" title="Quality of service"></a>Quality of service</h3><p>If you have a heavy processing and use multiple consumers on one queue, then you can achieve fair dispatching of messages sending only one at a time. There is a special method to define a number of <a href="https://www.rabbitmq.com/consumer-prefetch.html" target="_blank" rel="noopener">prefetched messages</a>.</p><h3 id="RabbitMQ-simulator"><a href="#RabbitMQ-simulator" class="headerlink" title="RabbitMQ simulator"></a>RabbitMQ simulator</h3><p>If you feel that you quite don’t get the idea behind message flow you can play with different exchange type and routing options on <a href="http://tryrabbitmq.com/" target="_blank" rel="noopener">RabbitMQ simulator</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Yet another RabbitMQ introduction. If you are looking for an article about RabbitMQ, there are plenty of them and most of them are really good. Nevertheless, I decided to make my own contribution. So considering an amount of information out there about RabbitMQ, what makes this article different? I will try to keep it short, meaningful and practical while not falling into a bottomless pit of details. I do not mean that there are something that is not worth to know about, just let’s try it this way. Consider it as TL;DR for the topic.&lt;br&gt;
    
    </summary>
    
    
      <category term="RabbitMQ" scheme="https://mikemadisonweb.github.io/tags/RabbitMQ/"/>
    
      <category term="AMQP" scheme="https://mikemadisonweb.github.io/tags/AMQP/"/>
    
  </entry>
  
  <entry>
    <title>Import XML file into database</title>
    <link href="https://mikemadisonweb.github.io/2017/01/08/import-xml-into-sql/"/>
    <id>https://mikemadisonweb.github.io/2017/01/08/import-xml-into-sql/</id>
    <published>2017-01-08T09:00:00.000Z</published>
    <updated>2019-12-08T15:50:11.154Z</updated>
    
    <content type="html"><![CDATA[<p>I will not talk about whether it’s a good idea or not to store dump in XML, let’s suppose you have this huge XML file and you need to load it in your database. Let’s find the most efficient way to do it.<br><a id="more"></a><br>In fact the bigger the file is the more problem you have because you need to think about import performance and memory consumption. Also, the schema of the data inside your dump may be messy or totally irrational. All this determines the required flexibility of your import method.</p><p>For the sake of this article, I will use <a href="https://archive.org/download/stackexchange" target="_blank" rel="noopener">stackoverflow comments dump</a> which is nearly 10Gb after unpacking.<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> comments (</span><br><span class="line">  <span class="string">"Id"</span> <span class="built_in">serial</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">  <span class="string">"PostId"</span> <span class="built_in">VARCHAR</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">"Score"</span> <span class="built_in">VARCHAR</span>(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">"Text"</span> <span class="built_in">TEXT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">"CreationDate"</span> <span class="built_in">DATE</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">"UserId"</span> <span class="built_in">VARCHAR</span>(<span class="number">255</span>) <span class="literal">NULL</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure></p><p>That’s would a table for our comments dataset. Column names taken from xml node attributes.</p><h3 id="Native-import-in-MySQL"><a href="#Native-import-in-MySQL" class="headerlink" title="Native import in MySQL"></a>Native import in MySQL</h3><p>To demonstrate how easy this stuff can be, let’s look at how MySQL handles that kind of task:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOAD</span> <span class="keyword">XML</span> <span class="keyword">LOCAL</span> <span class="keyword">INFILE</span> <span class="string">'/var/lib/mysql/dump/Comments.xml'</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> comments <span class="keyword">ROWS</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'&lt;row&gt;'</span>;</span><br></pre></td></tr></table></figure></p><p>The Mysql solution is short and simple, but it works only on version &gt;=5.5.  Column names associated with either node attributes or <code>field</code> nodes with required <code>name</code> attribute. In the last case value for the particular column will be taken from node text. If you are interested you can find more about it in <a href="https://dev.mysql.com/doc/refman/5.5/en/load-xml.html" target="_blank" rel="noopener">official Mysql docs</a>.</p><p>Import took just about 2 hours for our test XML dump.</p><p>Simplicity in MySQL came with a price, as it’s kind of limited in allowed XML formatting. That’s can be a huge problem for example if you import relational data.</p><h3 id="XML-processing-functions-in-PostgreSQL"><a href="#XML-processing-functions-in-PostgreSQL" class="headerlink" title="XML processing functions in PostgreSQL"></a>XML processing functions in PostgreSQL</h3><p>I decided to put MySQL example here for a reason. Not that MySQL lacks XML processing, it’s PostgreSQL that don’t have such a simple solution. Postgres have advanced functionality and that usually leads to overcomplicated solutions. When I was searching for a way to do XML import I stumbled upon <a href="http://stackoverflow.com/a/7628453" target="_blank" rel="noopener">this stackoverflow answer</a> which give me a hint on how to solve my problem but introduced a lot of custom user functions, which wasn’t necessary. I ended up with this:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> comments</span><br><span class="line">  <span class="keyword">SELECT</span> (xpath(<span class="string">'//row/@Id'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span>::<span class="built_in">int</span> <span class="keyword">AS</span> <span class="keyword">Id</span>,</span><br><span class="line">         (xpath(<span class="string">'//row/@PostId'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span>::<span class="built_in">int</span> <span class="keyword">AS</span> PostId,</span><br><span class="line">         (xpath(<span class="string">'//row/@Score'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span>::<span class="built_in">int</span> <span class="keyword">AS</span> Score,</span><br><span class="line">         (xpath(<span class="string">'//row/@Text'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span> <span class="keyword">AS</span> <span class="built_in">Text</span>,</span><br><span class="line">         (xpath(<span class="string">'//row/@CreationDate'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span>::<span class="built_in">date</span> <span class="keyword">AS</span> CreationDate,</span><br><span class="line">         (xpath(<span class="string">'//row/@UserId'</span>, x))[<span class="number">1</span>]::<span class="built_in">text</span>::<span class="built_in">int</span> <span class="keyword">AS</span> UserId</span><br><span class="line">  <span class="keyword">FROM</span> <span class="keyword">unnest</span>(xpath(<span class="string">'//row'</span>, pg_read_file(<span class="string">'dump/Comments.xml'</span>)::<span class="keyword">xml</span>)) x;</span><br></pre></td></tr></table></figure></p><p>XPath provide a lot of flexibility, this time we are not limited with specific XML format. This method have some non-obvious quirks though:</p><ul><li>Your dump should be in the data directory of Postgres. That’s the pg_read_file function requirement. There are some alternatives to it in Postgres, more on that matter in stackoverflow thread mentioned above.</li><li>As you can see XML field type can’t be directly converted to integer. You need a intermediate conversion to text.</li><li>Your dump shoudn’t have BOM. You should <a href="http://www.linuxask.com/questions/how-to-remove-bom-from-utf-8" target="_blank" rel="noopener">remove it</a> before running import otherwise you’ll receive an error.</li></ul><p>And the most important one: it fails on large XML files: <code>ERROR:  requested length too large</code>. So we either need to split our file on smaller pieces or use different approach.</p><h3 id="Import-using-Python"><a href="#Import-using-Python" class="headerlink" title="Import using Python"></a>Import using Python</h3><p>The key in succeeding controlling the whole process is to write your own external script. Obviously, you can’t beat above solutions in execution time, but you definitely can reduce memory consumption. </p><p>I used Python 3, lxml module to process dump and psycopg2 for the database connection. With my naive approach at first I got really slow performance, some major improvements were needed. To save you time I will post my final solution and then point out the most important parts:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> psycopg2</span><br><span class="line"><span class="keyword">from</span> psycopg2.extras <span class="keyword">import</span> execute_values</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> psutil</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sizeof_fmt</span><span class="params">(num, suffix=<span class="string">'B'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> [<span class="string">''</span>,<span class="string">'Ki'</span>,<span class="string">'Mi'</span>,<span class="string">'Gi'</span>,<span class="string">'Ti'</span>,<span class="string">'Pi'</span>,<span class="string">'Ei'</span>,<span class="string">'Zi'</span>]:</span><br><span class="line">        <span class="keyword">if</span> abs(num) &lt; <span class="number">1024.0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"%3.1f%s%s"</span> % (num, unit, suffix)</span><br><span class="line">        num /= <span class="number">1024.0</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"%.1f%s%s"</span> % (num, <span class="string">'Yi'</span>, suffix)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">import_xml</span><span class="params">(filename, connect, insert_command, batch = [], batch_size = <span class="number">1000</span>)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    cursor = connect.cursor()</span><br><span class="line">    process = psutil.Process(os.getpid())</span><br><span class="line">    <span class="keyword">for</span> event, element <span class="keyword">in</span> etree.iterparse(filename, events=(<span class="string">'end'</span>,), tag=<span class="string">'row'</span>):</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        row = [element.get(n) <span class="keyword">for</span> n <span class="keyword">in</span> (<span class="string">'PostId'</span>, <span class="string">'Score'</span>, <span class="string">'Text'</span>, <span class="string">'CreationDate'</span>, <span class="string">'UserId'</span>)]</span><br><span class="line">        batch.append(row)</span><br><span class="line">        <span class="comment"># Free memory</span></span><br><span class="line">        element.clear()</span><br><span class="line">        <span class="keyword">if</span> element.getprevious() <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">del</span>(element.getparent()[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># Save batch to DB</span></span><br><span class="line">        <span class="keyword">if</span> count % batch_size == <span class="number">0</span>:</span><br><span class="line">            execute_values(cursor, insert_command, batch)</span><br><span class="line">            print(<span class="string">"\033[?25lImported rows: &#123;&#125; | Memory usage: &#123;&#125;\r"</span>.format(count, sizeof_fmt(process.memory_info().rss)), sep=<span class="string">''</span>, end=<span class="string">''</span>, flush=<span class="literal">True</span>)</span><br><span class="line">            batch = []</span><br><span class="line">    <span class="comment"># Save the rest</span></span><br><span class="line">    <span class="keyword">if</span> len(batch):</span><br><span class="line">        execute_values(cursor, insert_command, batch)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">import_dump</span><span class="params">(db_name = <span class="string">'fts'</span>, db_host = <span class="string">'postgres-db'</span>, db_user = <span class="string">'postgres'</span>, db_pass = <span class="string">''</span>, db_table = <span class="string">'comments'</span>)</span>:</span></span><br><span class="line">    filename = <span class="string">'/dump/Comments.xml'</span></span><br><span class="line">    start_date = datetime.datetime.now()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Import data from &#123;&#125;"</span>.format(filename))</span><br><span class="line">    connect = psycopg2.connect(database=db_name, user=db_user, host=db_host, password=db_pass)</span><br><span class="line">    connect.autocommit = <span class="literal">True</span></span><br><span class="line">    cursor = connect.cursor()</span><br><span class="line"></span><br><span class="line">    insert_command = <span class="string">'INSERT INTO &#123;&#125; (PostId, Score, Text, CreationDate, UserId) VALUES %s'</span>.format(db_table)</span><br><span class="line">    import_xml(filename, connect, insert_command)</span><br><span class="line">    connect.close()</span><br><span class="line"></span><br><span class="line">    end_date = datetime.datetime.now()</span><br><span class="line">    seconds = (end_date - start_date).total_seconds()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"\nExecuted in &#123;&#125;s"</span>.format(seconds))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    import_dump()</span><br></pre></td></tr></table></figure></p><ul><li><code>etree.iterparse</code> returns iterator providing (event, element) pairs. In contrast with <code>etree.parse</code> iterator provide a way to save memory, you just need to remove previously parsed nodes which you don’t need anymore.</li><li>Batch insert is much faster than separate insert for each record. You can tweak <code>batch_size</code> property in order to locate a sweet spot in performance.</li><li>psutil module is not required, it’s just to visualize script memory consumption.</li></ul><p>All in all, it took 2 hours 18 minutes to import 10Gb of stackoverflow comments and used 25Mb of RAM only. Great results!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I will not talk about whether it’s a good idea or not to store dump in XML, let’s suppose you have this huge XML file and you need to load it in your database. Let’s find the most efficient way to do it.&lt;br&gt;
    
    </summary>
    
    
      <category term="PostgreSQL" scheme="https://mikemadisonweb.github.io/tags/PostgreSQL/"/>
    
      <category term="XML import" scheme="https://mikemadisonweb.github.io/tags/XML-import/"/>
    
      <category term="Python" scheme="https://mikemadisonweb.github.io/tags/Python/"/>
    
      <category term="MySQL" scheme="https://mikemadisonweb.github.io/tags/MySQL/"/>
    
      <category term="SQL" scheme="https://mikemadisonweb.github.io/tags/SQL/"/>
    
  </entry>
  
</feed>
